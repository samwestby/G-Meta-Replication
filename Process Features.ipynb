{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be8af783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf9e25",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nltk.download() # follow the prompts to download \"stopwords\"\n",
    "# stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "874cc6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag o words feature vector\n",
    "stops = stopwords.words('english')\n",
    "def text_preprocess(text:str):\n",
    "    # Ignoring case\n",
    "    text = text.lower()\n",
    "    # Ignoring punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Ignoring frequent words that don’t contain much information, called stop words, like “a,” “of,” etc.\n",
    "    text = text.split(' ')\n",
    "    text = [word for word in text if not word in stops]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def aggregate_features(x):\n",
    "    return [*x['word_bag'], *x['bill_type_vec'], *x['control_vec'], *x['pass_law_vec']]\n",
    "\n",
    "\n",
    "def one_hot_encoder(data:list):\n",
    "    n_types = len(set(data))\n",
    "    type_key = list(set(data))\n",
    "    encoded = [None]*len(data)\n",
    "    for i, x in enumerate(data):\n",
    "        vec = [0]*n_types\n",
    "        index = type_key.index(x)\n",
    "        vec[index] = 1\n",
    "        encoded[i] = vec\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "05a3493a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words completed\n"
     ]
    }
   ],
   "source": [
    "bill_features = pd.read_csv('/home/sam/neu/gml/data/congress/original/bills_features_label.csv')\n",
    "bill_features = bill_features\n",
    "clean_title_text = bill_features['title_text'].apply(text_preprocess)\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 118)\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocaulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_title_text)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features_normed = normalize(train_data_features)\n",
    "print('Bag of words completed')\n",
    "bill_features['word_bag'] = list(train_data_features_normed)\n",
    "#  add party_control to the feature vector\n",
    "bill_features['control_vec'] = bill_features['party_control_congress'].apply(\n",
    "                                                    lambda x: [x/100-1])\n",
    "bill_features['bill_type_vec'] = one_hot_encoder(list(bill_features['bill_type']))\n",
    "bill_features['pass_law_vec'] = bill_features['pass_law'].apply(lambda x: [x])\n",
    "bill_features['vector'] = bill_features.apply(aggregate_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "858507e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = bill_features[['bill_id', 'vector']]\n",
    "with open('/home/sam/neu/gml/data/congress/original/features_df.csv', 'wb') as f:\n",
    "    df_features.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a34e4d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_features = np.load('/home/sam/neu/gml/G-Meta/G-Meta_Data/FirstMM_DB/features.npy', allow_pickle=True)\n",
    "mm_features[0].dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
