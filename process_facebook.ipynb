{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dgl\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network to DGLGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/sam/neu/gml/data/facebook'\n",
    "edges_df = pd.read_csv(os.path.join(path, 'facebook_large/musae_facebook_edges.csv'))\n",
    "G_facebook = nx.Graph()\n",
    "G_facebook = nx.from_pandas_edgelist(edges_df, 'id_1', 'id_2')\n",
    "digraph = nx.DiGraph(G_facebook)\n",
    "K = dgl.DGLGraph()\n",
    "K.from_networkx(digraph)\n",
    "dgl_g = [K]\n",
    "with open(path + '/graph_dgl.pkl', 'wb') as f:\n",
    "    pickle.dump(dgl_g, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>facebook_id</th>\n",
       "      <th>page_name</th>\n",
       "      <th>page_type</th>\n",
       "      <th>page_type_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>145647315578475</td>\n",
       "      <td>The Voice of China 中国好声音</td>\n",
       "      <td>tvshow</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>191483281412</td>\n",
       "      <td>U.S. Consulate General Mumbai</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>144761358898518</td>\n",
       "      <td>ESET</td>\n",
       "      <td>company</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>568700043198473</td>\n",
       "      <td>Consulate General of Switzerland in Montreal</td>\n",
       "      <td>government</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1408935539376139</td>\n",
       "      <td>Mark Bailey MP - Labor for Miller</td>\n",
       "      <td>politician</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id       facebook_id                                     page_name  \\\n",
       "0   0   145647315578475                      The Voice of China 中国好声音   \n",
       "1   1      191483281412                 U.S. Consulate General Mumbai   \n",
       "2   2   144761358898518                                          ESET   \n",
       "3   3   568700043198473  Consulate General of Switzerland in Montreal   \n",
       "4   4  1408935539376139             Mark Bailey MP - Labor for Miller   \n",
       "\n",
       "    page_type  page_type_int  \n",
       "0      tvshow              0  \n",
       "1  government              1  \n",
       "2     company              2  \n",
       "3  government              1  \n",
       "4  politician              3  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/home/sam/neu/gml/data/facebook'\n",
    "labels_df = pd.read_csv(os.path.join(path, 'facebook_large/musae_facebook_target.csv'))\n",
    "labels_key = ['tvshow', 'government', 'company', 'politician']\n",
    "labels_df['page_type_int'] = labels_df['page_type'].apply(lambda x: labels_key.index(x))\n",
    "labels_df['subgraph_node'] = labels_df['id'].apply(lambda x: '0_'+str(x))\n",
    "labels_dict = dict(zip(labels_df['subgraph_node'], labels_df['page_type_int']))\n",
    "with open(path + '/label.pkl', 'wb') as f:\n",
    "    pickle.dump(labels_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create network features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag o words feature vector\n",
    "stops = stopwords.words('english')\n",
    "def text_preprocess(text:str):\n",
    "    # Ignoring case\n",
    "    text = text.lower()\n",
    "    # Ignoring punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # Ignoring frequent words that don’t contain much information, called stop words, like “a,” “of,” etc.\n",
    "    text = text.split(' ')\n",
    "    text = [word for word in text if not word in stops]\n",
    "    text = ' '.join(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of words completed\n"
     ]
    }
   ],
   "source": [
    "clean_title_text = labels_df['page_name'].apply(text_preprocess)\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 256)\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocaulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_title_text)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n",
    "train_data_features_normed = normalize(train_data_features)\n",
    "print('Bag of words completed')\n",
    "labels_df['vector'] = list(train_data_features_normed)\n",
    "\n",
    "\n",
    "features = np.array([np.array(x) for x in labels_df['vector']])\n",
    "np.save(path + '/features.npy', features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train.csv, test.csv, and val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(labels_dict, orient='index').reset_index().rename(columns={\"index\": \"name\", 0: \"label\"})\n",
    "\n",
    "train_label = [2, 3]\n",
    "other_label = [0, 1]\n",
    "\n",
    "other_df = df[df['label'].isin(other_label)]\n",
    "# First half\n",
    "val_df = other_df.iloc[: int(len(other_df)/2)]\n",
    "# Second half\n",
    "test_df = other_df.iloc[int(len(other_df)/2) :]\n",
    "train_df = df[df['label'].isin(train_label)]\n",
    "\n",
    "train_df.reset_index(drop = True).to_csv(path + '/train.csv')\n",
    "val_df.reset_index(drop = True).to_csv(path + '/val.csv')\n",
    "test_df.reset_index(drop = True).to_csv(path + '/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
